{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1l-fxI1qqGwx",
        "outputId": "2e31dbf3-e2ab-4cc0-eaa1-a6033d0ccbcb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: googletrans==3.1.0a0 in /usr/local/lib/python3.10/dist-packages (3.1.0a0)\n",
            "Requirement already satisfied: httpx==0.13.3 in /usr/local/lib/python3.10/dist-packages (from googletrans==3.1.0a0) (0.13.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==3.1.0a0) (2024.7.4)\n",
            "Requirement already satisfied: hstspreload in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==3.1.0a0) (2024.8.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==3.1.0a0) (1.3.1)\n",
            "Requirement already satisfied: chardet==3.* in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==3.1.0a0) (3.0.4)\n",
            "Requirement already satisfied: idna==2.* in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==3.1.0a0) (2.10)\n",
            "Requirement already satisfied: rfc3986<2,>=1.3 in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==3.1.0a0) (1.5.0)\n",
            "Requirement already satisfied: httpcore==0.9.* in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==3.1.0a0) (0.9.1)\n",
            "Requirement already satisfied: h11<0.10,>=0.8 in /usr/local/lib/python3.10/dist-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans==3.1.0a0) (0.9.0)\n",
            "Requirement already satisfied: h2==3.* in /usr/local/lib/python3.10/dist-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans==3.1.0a0) (3.2.0)\n",
            "Requirement already satisfied: hyperframe<6,>=5.2.0 in /usr/local/lib/python3.10/dist-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==3.1.0a0) (5.2.0)\n",
            "Requirement already satisfied: hpack<4,>=3.0 in /usr/local/lib/python3.10/dist-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==3.1.0a0) (3.0.0)\n",
            "Traduction terminée. Le fichier traduit a été sauvegardé.\n"
          ]
        }
      ],
      "source": [
        "#------------------------------- Tradiction --------------------------#\n",
        "!pip install googletrans==3.1.0a0\n",
        "import pandas as pd\n",
        "from googletrans import Translator\n",
        "\n",
        "# Lire le fichier CSV\n",
        "df = pd.read_csv('/content/email.csv')\n",
        "\n",
        "# Initialiser le traducteur\n",
        "translator = Translator()\n",
        "\n",
        "# Fonction pour traduire un message\n",
        "def translate_message(message, dest_lang='mg'):\n",
        "    try:\n",
        "        translation = translator.translate(message, dest=dest_lang)\n",
        "        return translation.text\n",
        "    except Exception as e:\n",
        "        print(f\"Error translating message: {e}\")\n",
        "        return message  # Retourne le message original en cas d'erreur\n",
        "\n",
        "# Traduire les messages de la colonne 'Message'\n",
        "df['Message Traduit'] = df['Message'].apply(lambda x: translate_message(x, dest_lang='mg'))\n",
        "\n",
        "# Sauvegarder le fichier avec les messages traduits\n",
        "df.to_csv('/content/email_traduit.csv', index=False)\n",
        "\n",
        "print(\"Traduction terminée. Le fichier traduit a été sauvegardé.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install the necessary packages\n",
        "!pip install googletrans deep-translator\n",
        "import pandas as pd\n",
        "from deep_translator import GoogleTranslator\n",
        "\n",
        "# Lire le fichier CSV\n",
        "df = pd.read_csv('/content/email_traduit.csv')\n",
        "\n",
        "# Initialiser le traducteur\n",
        "translator = GoogleTranslator(source='auto', target='mg')\n",
        "\n",
        "# Fonction pour traduire un message\n",
        "def translate_message(message):\n",
        "    try:\n",
        "        return translator.translate(message)\n",
        "    except Exception as e:\n",
        "        print(f\"Error translating message: {e}\")\n",
        "        return message  # Retourne le message original en cas d'erreur\n",
        "\n",
        "# Traduire les messages de la colonne 'Message'\n",
        "df['Message Traduit'] = df['Message'].apply(translate_message)\n",
        "\n",
        "# Sauvegarder le fichier avec les messages traduits\n",
        "df.to_csv('/content/email_traduit_1.csv', index=False)\n",
        "\n",
        "print(\"Traduction terminée. Le fichier traduit a été sauvegardé.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CNA7e3OByV2e",
        "outputId": "f34f25ed-e4b5-40b5-fb5c-000fe2acfeca"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: googletrans in /usr/local/lib/python3.10/dist-packages (3.1.0a0)\n",
            "Collecting deep-translator\n",
            "  Downloading deep_translator-1.11.4-py3-none-any.whl.metadata (30 kB)\n",
            "Requirement already satisfied: httpx==0.13.3 in /usr/local/lib/python3.10/dist-packages (from googletrans) (0.13.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans) (2024.7.4)\n",
            "Requirement already satisfied: hstspreload in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans) (2024.8.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans) (1.3.1)\n",
            "Requirement already satisfied: chardet==3.* in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans) (3.0.4)\n",
            "Requirement already satisfied: idna==2.* in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans) (2.10)\n",
            "Requirement already satisfied: rfc3986<2,>=1.3 in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans) (1.5.0)\n",
            "Requirement already satisfied: httpcore==0.9.* in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans) (0.9.1)\n",
            "Requirement already satisfied: h11<0.10,>=0.8 in /usr/local/lib/python3.10/dist-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans) (0.9.0)\n",
            "Requirement already satisfied: h2==3.* in /usr/local/lib/python3.10/dist-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans) (3.2.0)\n",
            "Requirement already satisfied: hyperframe<6,>=5.2.0 in /usr/local/lib/python3.10/dist-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans) (5.2.0)\n",
            "Requirement already satisfied: hpack<4,>=3.0 in /usr/local/lib/python3.10/dist-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans) (3.0.0)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.9.1 in /usr/local/lib/python3.10/dist-packages (from deep-translator) (4.12.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from deep-translator) (2.32.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4<5.0.0,>=4.9.1->deep-translator) (2.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.23.0->deep-translator) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.23.0->deep-translator) (2.0.7)\n",
            "Downloading deep_translator-1.11.4-py3-none-any.whl (42 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.3/42.3 kB\u001b[0m \u001b[31m649.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: deep-translator\n",
            "Successfully installed deep-translator-1.11.4\n",
            "Traduction terminée. Le fichier traduit a été sauvegardé.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#------------------------------- RandomForestClassifier --------------------------#\n",
        "import pandas as pd\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "import joblib\n",
        "\n",
        "# Fonction pour nettoyer le texte\n",
        "def clean_text(text):\n",
        "    # Supprimer les caractères spéciaux, les chiffres, et convertir en minuscules\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', str(text))\n",
        "    return text.lower()\n",
        "\n",
        "# Lire le fichier CSV avec les messages traduits\n",
        "df = pd.read_csv('/content/email_traduit.csv')\n",
        "\n",
        "# Nettoyage des données\n",
        "df['Message Traduit'] = df['Message Traduit'].apply(clean_text)\n",
        "\n",
        "# Préparer les données pour l'entraînement\n",
        "X = df['Message Traduit']\n",
        "y = df['Category']  # Remplacez 'Label' par le nom de la colonne qui contient les étiquettes\n",
        "\n",
        "# Vectorisation des textes\n",
        "vectorizer = TfidfVectorizer(max_features=5000)\n",
        "X_tfidf = vectorizer.fit_transform(X)\n",
        "\n",
        "# Diviser les données en ensembles d'entraînement et de test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Entraînement du modèle RandomForestClassifier\n",
        "clf_rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "clf_rf.fit(X_train, y_train)\n",
        "\n",
        "# Test du modèle\n",
        "y_pred_rf = clf_rf.predict(X_test)\n",
        "\n",
        "# Évaluation des performances du modèle\n",
        "print(\"Accuracy (RandomForest):\", accuracy_score(y_test, y_pred_rf))\n",
        "print(\"Classification Report (RandomForest):\\n\", classification_report(y_test, y_pred_rf))\n",
        "\n",
        "# Sauvegarde du modèle entraîné avec joblib\n",
        "model_filename_rf = '/content/sample_data/random_forest_model.joblib'\n",
        "joblib.dump(clf_rf, model_filename_rf)\n",
        "print(f\"Modèle RandomForest sauvegardé sous le nom {model_filename_rf}\")\n",
        "\n",
        "# Sauvegarde du vectorizer\n",
        "vectorizer_filename_rf = '/content/sample_data/tfidf_vectorizer_random.joblib'\n",
        "joblib.dump(vectorizer, vectorizer_filename_rf)\n",
        "print(f\"Vectorizer RandomForest sauvegardé sous le nom {vectorizer_filename_rf}\")\n",
        "\n",
        "# Charger le modèle et le vectorizer pour faire des prédictions\n",
        "loaded_model_rf = joblib.load(model_filename_rf)\n",
        "loaded_vectorizer_rf = joblib.load(vectorizer_filename_rf)\n",
        "\n",
        "# Exemple de prédiction sur un nouveau message\n",
        "new_message = input(\"Entrer votre message: \")\n",
        "new_message_tfidf = loaded_vectorizer_rf.transform([clean_text(new_message)])  # Passer le message sous forme de liste\n",
        "prediction_rf = loaded_model_rf.predict(new_message_tfidf)\n",
        "\n",
        "print(f\"Prédiction pour le nouveau message (RandomForest): {prediction_rf[0]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "54oebs01mrQi",
        "outputId": "47d3b3e8-a98c-4150-91dd-424e911cb893"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy (RandomForest): 0.9730941704035875\n",
            "Classification Report (RandomForest):\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.97      1.00      0.98       958\n",
            "        spam       1.00      0.81      0.89       157\n",
            "\n",
            "    accuracy                           0.97      1115\n",
            "   macro avg       0.98      0.90      0.94      1115\n",
            "weighted avg       0.97      0.97      0.97      1115\n",
            "\n",
            "Modèle RandomForest sauvegardé sous le nom /content/sample_data/random_forest_model.joblib\n",
            "Vectorizer RandomForest sauvegardé sous le nom /content/sample_data/tfidf_vectorizer_random.joblib\n",
            "Entrer votre message: salama tsara daholo ve ianareo\n",
            "Prédiction pour le nouveau message (RandomForest): ham\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#---------------------------- Regression Logistique -------------------------------#\n",
        "import pandas as pd\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "import joblib\n",
        "\n",
        "# Fonction pour nettoyer le texte\n",
        "def clean_text(text):\n",
        "    # Supprimer les caractères spéciaux, les chiffres, et convertir en minuscules\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', str(text))\n",
        "    return text.lower()\n",
        "\n",
        "# Lire le fichier CSV avec les messages traduits\n",
        "df = pd.read_csv('/content/email_traduit.csv')\n",
        "\n",
        "# Nettoyage des données\n",
        "df['Message Traduit'] = df['Message Traduit'].apply(clean_text)\n",
        "\n",
        "# Préparation des données\n",
        "X = df['Message Traduit']  # Les textes traduits nettoyés\n",
        "y = df['Category']  # Les étiquettes (spam ou ham)\n",
        "\n",
        "# Vectorisation des textes en utilisant TfidfVectorizer\n",
        "vectorizer = TfidfVectorizer()\n",
        "X_tfidf = vectorizer.fit_transform(X)\n",
        "\n",
        "# Séparation des données en ensembles d'entraînement et de test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Entraînement du modèle LogisticRegression\n",
        "clf_lr = LogisticRegression(random_state=42)\n",
        "clf_lr.fit(X_train, y_train)\n",
        "\n",
        "# Test du modèle\n",
        "y_pred_lr = clf_lr.predict(X_test)\n",
        "\n",
        "# Évaluation des performances du modèle\n",
        "print(\"Accuracy (Logistic Regression):\", accuracy_score(y_test, y_pred_lr))\n",
        "print(\"Classification Report (Logistic Regression):\\n\", classification_report(y_test, y_pred_lr))\n",
        "\n",
        "# Sauvegarde du modèle entraîné avec joblib\n",
        "model_filename_lr = '/content/sample_data/logistic_regression_model.joblib'\n",
        "joblib.dump(clf_lr, model_filename_lr)\n",
        "print(f\"Modèle Logistic Regression sauvegardé sous le nom {model_filename_lr}\")\n",
        "\n",
        "# Sauvegarde du vectorizer\n",
        "vectorizer_filename_lr = '/content/sample_data/tfidf_vectorizer_regretion.joblib'\n",
        "joblib.dump(vectorizer, vectorizer_filename_lr)\n",
        "print(f\"Vectorizer Logistic Regression sauvegardé sous le nom {vectorizer_filename_lr}\")\n",
        "\n",
        "# Charger le modèle et le vectorizer pour faire des prédictions\n",
        "loaded_model_lr = joblib.load(model_filename_lr)\n",
        "loaded_vectorizer_lr = joblib.load(vectorizer_filename_lr)\n",
        "\n",
        "# Exemple de prédiction sur un nouveau message\n",
        "new_message = input(\"Entrer votre message: \")\n",
        "new_message_tfidf = loaded_vectorizer_lr.transform([clean_text(new_message)])  # Passer le message sous forme de liste\n",
        "prediction_lr = loaded_model_lr.predict(new_message_tfidf)\n",
        "\n",
        "print(f\"Prédiction pour le nouveau message (Logistic Regression): {prediction_lr[0]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RlNzQtHOoO29",
        "outputId": "9bde437c-eb63-4c41-dbcc-db03224559a1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy (Logistic Regression): 0.967713004484305\n",
            "Classification Report (Logistic Regression):\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.96      1.00      0.98       958\n",
            "        spam       0.99      0.78      0.87       157\n",
            "\n",
            "    accuracy                           0.97      1115\n",
            "   macro avg       0.98      0.89      0.93      1115\n",
            "weighted avg       0.97      0.97      0.97      1115\n",
            "\n",
            "Modèle Logistic Regression sauvegardé sous le nom /content/sample_data/logistic_regression_model.joblib\n",
            "Vectorizer Logistic Regression sauvegardé sous le nom /content/sample_data/tfidf_vectorizer_regretion.joblib\n",
            "Entrer votre message: Nitady teny mety aho mba hisaorana anao amin'ity fofonaina ity. Mampanantena aho fa tsy horaisiko ho tsinontsinona ny fanampianao ary hotanterahiko ny fampanantenako. Nahafinaritra sy fitahiana foana ianao.\n",
            "Prédiction pour le nouveau message (Logistic Regression): ham\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "3P1BjR1noOMq"
      }
    }
  ]
}